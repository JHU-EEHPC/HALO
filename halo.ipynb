{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from core.configs import cfg\n",
    "from core.train_learners import Test\n",
    "from core.datasets.build import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args_str: str = None):\n",
    "    parser = argparse.ArgumentParser(description=\"Active Domain Adaptive Semantic Segmentation Training\")\n",
    "    parser.add_argument(\"-cfg\",\n",
    "                        \"--config-file\",\n",
    "                        default=\"\",\n",
    "                        metavar=\"FILE\",\n",
    "                        help=\"path to config file\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--proctitle\",\n",
    "                        type=str,\n",
    "                        default=\"HALO\",\n",
    "                        help=\"allow a process to change its title\", )\n",
    "    parser.add_argument(\n",
    "        \"opts\",\n",
    "        help=\"Modify config options using the command-line\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER\n",
    "    )\n",
    "\n",
    "    args_list = args_str.split() if args_str else None\n",
    "    args = parser.parse_args(args_list)\n",
    "\n",
    "    if args.opts is not None and args.opts != []:\n",
    "        args.opts[-1] = args.opts[-1].strip('\\r\\n')\n",
    "\n",
    "    cfg.set_new_allowed(True)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args(\"-cfg configs/gtav/test.yaml\")\n",
    "learner = Test(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = cfg.INPUT.INPUT_SIZE_TEST\n",
    "trans = transform.Compose([\n",
    "    transform.Resize((h, w), resize_label=False),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD, to_bgr255=cfg.INPUT.TO_BGR255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"datasets/cityscapes/leftImg8bit/train/aachen/aachen_000133_000019_leftImg8bit.png\"\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = trans(img, torch.randn(1, h, w))[0]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = learner.forward(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, decoder_out = out\n",
    "print(\"output.shape: \", output.shape)\n",
    "print(\"decoder_out.shape: \", decoder_out.shape)\n",
    "size = output.shape[-2:]\n",
    "print(\"size: \", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.active.build import select_pixels_to_label\n",
    "from core.active.floating_region import FloatingRegionScore\n",
    "\n",
    "per_region_pixels = (2 * cfg.ACTIVE.RADIUS_K + 1) ** 2\n",
    "active_radius = cfg.ACTIVE.RADIUS_K\n",
    "mask_radius = cfg.ACTIVE.MASK_RADIUS_K\n",
    "active_ratio = cfg.ACTIVE.RATIO / len(cfg.ACTIVE.SELECT_ITER)\n",
    "uncertainty_type = cfg.ACTIVE.UNCERTAINTY\n",
    "purity_type = cfg.ACTIVE.PURITY\n",
    "K = cfg.ACTIVE.K\n",
    "num_pixel_cur = size[0] * size[1]\n",
    "\n",
    "decoder_out = F.interpolate(decoder_out, size=size, mode='bilinear', align_corners=True)\n",
    "\n",
    "floating_region_score = FloatingRegionScore(\n",
    "    in_channels=19, size=2*active_radius+1, purity_type=purity_type, K=K)\n",
    "\n",
    "score, _, _ = floating_region_score(\n",
    "    output, decoder_out=decoder_out, normalize=cfg.ACTIVE.NORMALIZE,\n",
    "    unc_type=uncertainty_type, pur_type=purity_type)\n",
    "\n",
    "# active_regions = math.ceil(num_pixel_cur * active_ratio / per_region_pixels)\n",
    "# score, active, selected, active_mask = select_pixels_to_label(\n",
    "#     score, active_regions, active_radius, mask_radius,\n",
    "#     active, selected, active_mask, ground_truth\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of elements to be set to True (top 5%)\n",
    "num_elements = score.numel()\n",
    "num_true_elements = int(num_elements * 0.05)\n",
    "\n",
    "# Flatten the tensor and sort it in descending order\n",
    "flattened = score.flatten()\n",
    "sorted_tensor, _ = torch.sort(flattened, descending=True)\n",
    "\n",
    "# Get the threshold value for the top 5%\n",
    "threshold = sorted_tensor[num_true_elements]\n",
    "\n",
    "# Create a new tensor with the same shape as the original tensor\n",
    "active_mask = torch.zeros_like(score, dtype=torch.bool)\n",
    "\n",
    "# Set elements to True if they are greater than or equal to the threshold\n",
    "active_mask[score >= threshold] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pixels_to_label(score, active_regions, active_radius, mask_radius,\n",
    "                           active, selected, active_mask, ground_truth):\n",
    "    for pixel in range(active_regions):\n",
    "        values, indices_h = torch.max(score, dim=0)\n",
    "        max_value, indices_w = torch.max(values, dim=0)\n",
    "        if max_value == -float('inf'):\n",
    "            break\n",
    "        w = indices_w.item()\n",
    "        h = indices_h[w].item()\n",
    "\n",
    "        active_start_w = w - active_radius if w - active_radius >= 0 else 0\n",
    "        active_start_h = h - active_radius if h - active_radius >= 0 else 0\n",
    "        active_end_w = w + active_radius + 1\n",
    "        active_end_h = h + active_radius + 1\n",
    "\n",
    "        mask_start_w = w - mask_radius if w - mask_radius >= 0 else 0\n",
    "        mask_start_h = h - mask_radius if h - mask_radius >= 0 else 0\n",
    "        mask_end_w = w + mask_radius + 1\n",
    "        mask_end_h = h + mask_radius + 1\n",
    "\n",
    "        # mask out\n",
    "        score[mask_start_h:mask_end_h,\n",
    "              mask_start_w:mask_end_w] = -float('inf')\n",
    "        active[mask_start_h:mask_end_h,\n",
    "               mask_start_w:mask_end_w] = True\n",
    "        selected[active_start_h:active_end_h,\n",
    "                 active_start_w:active_end_w] = True\n",
    "        # active sampling\n",
    "        active_mask[active_start_h:active_end_h, active_start_w:active_end_w] = \\\n",
    "            ground_truth[active_start_h:active_end_h,\n",
    "                         active_start_w:active_end_w]\n",
    "\n",
    "    return score, active, selected, active_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices_h = torch.max(score, dim=0)\n",
    "max_value, indices_w = torch.max(values, dim=0)\n",
    "w = indices_w.item()\n",
    "h = indices_h[w].item()\n",
    "\n",
    "active_start_w = w - active_radius if w - active_radius >= 0 else 0\n",
    "active_start_h = h - active_radius if h - active_radius >= 0 else 0\n",
    "active_end_w = w + active_radius + 1\n",
    "active_end_h = h + active_radius + 1\n",
    "\n",
    "mask_start_w = w - mask_radius if w - mask_radius >= 0 else 0\n",
    "mask_start_h = h - mask_radius if h - mask_radius >= 0 else 0\n",
    "mask_end_w = w + mask_radius + 1\n",
    "mask_end_h = h + mask_radius + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITYSCAPES_MEAN = torch.Tensor(\n",
    "    [123.675, 116.28, 103.53]).reshape(1, 1, 3).numpy()\n",
    "CITYSCAPES_STD = torch.Tensor([58.395, 57.12, 57.375]).reshape(1, 1, 3).numpy()\n",
    "\n",
    "img_np = img.permute(1, 2, 0).detach().numpy()\n",
    "img_np = (img_np * CITYSCAPES_STD + CITYSCAPES_MEAN).astype(np.uint8)\n",
    "score_np = score.detach().numpy()\n",
    "active_mask_np = active_mask.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "cmap1='gray'\n",
    "cmap2='viridis'\n",
    "alpha=0.7\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, constrained_layout=True, figsize=(12, 12), dpi=300)\n",
    "\n",
    "title = \"HALO pixel selection\"\n",
    "plt.suptitle(title, fontsize=16)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "axes[0].set_title('Original image')\n",
    "axes[0].imshow(img_np)\n",
    "\n",
    "axes[1].set_title('Pixels score')\n",
    "axes[1].imshow(img_np, cmap=cmap1)\n",
    "# im_score = axes[1].imshow(score_np,  cmap=cmap2, alpha=alpha)\n",
    "axes[1].imshow(score_np, cmap=cmap2, alpha=alpha)\n",
    "# divider = make_axes_locatable(axes[1])\n",
    "# cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "# plt.colorbar(im_score, cax=cax, location='right')\n",
    "\n",
    "axes[2].set_title('Selected Pixels (top 5%)')\n",
    "axes[2].imshow(img_np, cmap=cmap1)\n",
    "axes[2].imshow(active_mask_np, cmap='autumn', alpha=0.3)\n",
    "\n",
    "img_buf = io.BytesIO()\n",
    "plt.savefig(img_buf, format='png', bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "im = Image.open(img_buf).convert('RGB')\n",
    "plt.axis('off')\n",
    "plt.imshow(im)\n",
    "\n",
    "# im_np = np.array(im)\n",
    "# plt.imshow(im_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
