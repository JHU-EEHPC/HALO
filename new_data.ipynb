{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys:  dict_keys(['labels', '00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00053', '00054', '00055', '00056', '00057', '00058', '00059', '00060', '00061', '00062', '00063', '00064', '00065', '00066', '00067', '00068', '00069', '00070', '00071', '00072', '00073', '00074', '00075', '00076', '00077', '00078', '00079', '00080', '00081', '00082', '00083', '00084', '00085', '00086', '00087', '00088', '00089', '00090', '00091', '00092', '00093', '00094', '00095', '00096', '00097', '00098', '00099', '00100', '00101', '00102', '00103', '00104', '00105', '00106', '00107', '00108', '00109', '00110', '00111', '00112', '00113', '00114', '00115', '00116', '00117', '00118', '00119', '00120', '00121', '00122', '00123', '00124', '00125', '00126', '00127', '00128', '00129', '00130', '00131', '00132', '00133', '00134', '00135', '00136', '00137', '00138', '00139', '00140', '00141', '00142', '00143', '00144', '00145', '00146', '00147', '00148', '00149', '00150', '00151', '00152', '00153', '00154', '00155', '00156', '00157', '00158', '00159', '00160', '00161', '00162', '00163', '00164', '00165', '00166', '00167', '00168', '00169', '00170', '00171', '00172', '00173', '00174', '00175', '00176', '00177', '00178', '00179', '00180', '00181', '00182', '00183', '00184', '00185', '00186', '00187', '00188', '00189', '00190', '00191', '00192', '00193', '00194', '00195', '00196', '00197', '00198', '00199'])\n",
      "labels:  ['person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle', 'traffic sign', 'traffic light', 'pole', 'fence', 'wall', 'building', 'road', 'sky', 'sidewalk', 'vegetation', 'tree', 'terrain']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "categories = ['bicycle', 'bus', 'motorcycle', 'rider', 'traffic light']\n",
    "category = 'bicycle'\n",
    "file_path = f'datasets/halo_extra_data/hipie/{category}_annotations.pt'\n",
    "data = torch.load(file_path)\n",
    "\n",
    "print(\"keys: \", data.keys())\n",
    "labels = data.pop('labels')\n",
    "print(\"labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid2name = {\n",
    "    0: \"road\",\n",
    "    1: \"sidewalk\",\n",
    "    2: \"building\",\n",
    "    3: \"wall\",\n",
    "    4: \"fence\",\n",
    "    5: \"pole\",\n",
    "    6: \"light\",\n",
    "    7: \"sign\",\n",
    "    8: \"vegetation\",\n",
    "    9: \"terrain\",\n",
    "    10: \"sky\",\n",
    "    11: \"person\",\n",
    "    12: \"rider\",\n",
    "    13: \"car\",\n",
    "    14: \"truck\",\n",
    "    15: \"bus\",\n",
    "    16: \"train\",\n",
    "    17: \"motocycle\",\n",
    "    18: \"bicycle\",\n",
    "    255: \"unknown\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainname2id:  {'road': 0, 'sidewalk': 1, 'building': 2, 'wall': 3, 'fence': 4, 'pole': 5, 'light': 6, 'sign': 7, 'vegetation': 8, 'terrain': 9, 'sky': 10, 'person': 11, 'rider': 12, 'car': 13, 'truck': 14, 'bus': 15, 'train': 16, 'motocycle': 17, 'bicycle': 18, 'unknown': 255, 'tree': 8, 'traffic light': 6, 'motorcycle': 17}\n"
     ]
    }
   ],
   "source": [
    "trainname2id = {v: k for k, v in trainid2name.items()}\n",
    "trainname2id[\"tree\"] = trainname2id[\"vegetation\"]\n",
    "trainname2id[\"traffic light\"] = trainname2id[\"light\"]\n",
    "trainname2id[\"motorcycle\"] = trainname2id[\"motocycle\"]\n",
    "print(\"trainname2id: \", trainname2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id:  00000\n",
      "keys:  dict_keys(['mask', 'info'])\n",
      "mask:  torch.Size([1500, 1500])\n",
      "info:  [{'id': 1, 'isthing': False, 'category_id': 18, 'area': 160021.0}, {'id': 2, 'isthing': False, 'category_id': 14, 'area': 354388.0}, {'id': 3, 'isthing': True, 'category_id': 7, 'area': 551563.0}, {'id': 4, 'isthing': False, 'category_id': 12, 'area': 1062544.0}]\n"
     ]
    }
   ],
   "source": [
    "first_item = next(iter(data.items()))\n",
    "\n",
    "image_id = first_item[0]\n",
    "print(\"image_id: \", image_id)\n",
    "\n",
    "keys = first_item[1].keys()\n",
    "print(\"keys: \", keys)\n",
    "\n",
    "mask = first_item[1]['mask']\n",
    "info = first_item[1]['info']\n",
    "print(\"mask: \", mask.shape)\n",
    "print(\"info: \", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_info(info) -> dict:\n",
    "    id2category = {0: 255}\n",
    "    for elem in info:\n",
    "        id2category[elem['id']] = elem['category_id']\n",
    "    return id2category\n",
    "\n",
    "def process_mask(mask, id2category) -> torch.Tensor:\n",
    "    unique = torch.unique(mask)\n",
    "    new_mask = mask.clone()\n",
    "    for i in unique:\n",
    "        category_id = id2category[i.item()]\n",
    "        if category_id == 255 or category_id == 0:\n",
    "            new_mask[new_mask == i.item()] = 255\n",
    "        else:\n",
    "            category_name = labels[category_id]\n",
    "            class_id = trainname2id[category_name]\n",
    "            new_mask[new_mask == i] = class_id\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d991d5eff0640328358d84ae14745ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from core.utils.misc import get_color_pallete\n",
    "\n",
    "new_masks = torch.zeros((len(data), 1500, 1500), dtype=torch.uint8)\n",
    "\n",
    "outdir = f'datasets/halo_extra_data/gtFine/train/{category}'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "for i, (k, v) in enumerate(tqdm(data.items())):\n",
    "    img_id = k\n",
    "    mask = v['mask']\n",
    "    info = v['info']\n",
    "    id2category = parse_info(info)\n",
    "    new_mask = process_mask(mask, id2category)\n",
    "    new_masks[i] = new_mask\n",
    "\n",
    "    # save masks\n",
    "    filepath_id = os.path.join(outdir, f'{category}_{img_id}_000019_gtFine_labelIds.png')\n",
    "    filepath_color = os.path.join(outdir, f'{category}_{img_id}_000019_gtFine_color.png')\n",
    "\n",
    "    png_id = new_mask.numpy()\n",
    "    png_id = Image.fromarray(png_id)\n",
    "    png_id = png_id.convert('L')\n",
    "    png_id.save(filepath_id)\n",
    "\n",
    "    png_color = new_mask.numpy()\n",
    "    png_color = get_color_pallete(png_color)\n",
    "    png_color.save(filepath_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_palette(npimg):\n",
    "    out_img = Image.fromarray(npimg.astype('uint8')).convert('P')\n",
    "    cityspallete = [\n",
    "        128, 64, 128,\n",
    "        244, 35, 232,\n",
    "        70, 70, 70,\n",
    "        102, 102, 156,\n",
    "        190, 153, 153,\n",
    "        153, 153, 153,\n",
    "        250, 170, 30,\n",
    "        220, 220, 0,\n",
    "        107, 142, 35,\n",
    "        152, 251, 152,\n",
    "        0, 130, 180,\n",
    "        220, 20, 60,\n",
    "        255, 0, 0,\n",
    "        0, 0, 142,\n",
    "        0, 0, 70,\n",
    "        0, 60, 100,\n",
    "        0, 80, 100,\n",
    "        0, 0, 230,\n",
    "        119, 11, 32,\n",
    "    ]\n",
    "    out_img.putpalette(cityspallete)\n",
    "    return out_img\n",
    "\n",
    "def extract_color(c):\n",
    "    cityspallete = {\n",
    "            0 :  [128, 64,  128],\n",
    "            1 :  [244, 35,  232],\n",
    "            2 :  [70,  70,  70],\n",
    "            3 :  [102, 102, 156],\n",
    "            4 :  [190, 153, 153],\n",
    "            5 :  [153, 153, 153],\n",
    "            6 :  [250, 170, 30],\n",
    "            7 :  [220, 220, 0],\n",
    "            8 :  [107, 142, 35],\n",
    "            9 :  [152, 251, 152],\n",
    "            10 : [0,   130, 180],\n",
    "            11 : [220, 20,  60],\n",
    "            12 : [255, 0,   0],\n",
    "            13 : [0,   0,   142],\n",
    "            14 : [0,   0,   70],\n",
    "            15 : [0,   60,  100],\n",
    "            16 : [0,   80,  100],\n",
    "            17 : [0,   0,   230],\n",
    "            18 : [119, 11,  32],\n",
    "            255: [255,   255,   255]}\n",
    "    return [color/255 for color in cityspallete[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  datasets/cityscapes/gtFine/train/aachen/aachen_000000_000019_gtFine_labelIds.png\n",
      "mask_labelIds:  torch.Size([1024, 2048])\n",
      "mask_labelIds.unique:  tensor([ 0,  1,  3,  4,  7,  8, 11, 17, 20, 21, 22, 23, 24, 25, 26, 33],\n",
      "       dtype=torch.uint8)\n",
      "\n",
      "Path:  datasets/halo_extra_data/gtFine/train/bicycle/bicycle_00000_000019_gtFine_labelIds.png\n",
      "mask_labelIds:  torch.Size([1500, 1500])\n",
      "mask_labelIds.unique:  tensor([  0,   3,   8,  18, 255], dtype=torch.uint8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# mask_color = Image.open(\"datasets/cityscapes/gtFine/train/aachen/aachen_000000_000019_gtFine_color.png\")\n",
    "# # mask_color = Image.open(\"datasets/halo_extra_data/gtFine/train/bicycle/bicycle_00000_000019_gtFine_color.png\")\n",
    "# mask_color = torch.from_numpy(np.array(mask_color))\n",
    "# mask_color = mask_color.permute(2, 0, 1)\n",
    "# print(\"mask_color: \", mask_color.shape)\n",
    "\n",
    "paths = [\n",
    "    \"datasets/cityscapes/gtFine/train/aachen/aachen_000000_000019_gtFine_labelIds.png\",\n",
    "    \"datasets/halo_extra_data/gtFine/train/bicycle/bicycle_00000_000019_gtFine_labelIds.png\"\n",
    "    ]\n",
    "\n",
    "for path in paths:\n",
    "    # mask_labelIds = Image.open(\"datasets/cityscapes/gtFine/train/aachen/aachen_000000_000019_gtFine_labelIds.png\")\n",
    "    mask_labelIds = Image.open(path)\n",
    "    mask_labelIds = mask_labelIds.convert('L')\n",
    "    mask_labelIds = torch.from_numpy(np.array(mask_labelIds))\n",
    "    print(\"Path: \", path)\n",
    "    print(\"mask_labelIds: \", mask_labelIds.shape)\n",
    "    print(\"mask_labelIds.unique: \", mask_labelIds.unique())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3,  ..., 8, 8, 8],\n",
       "        [3, 3, 3,  ..., 8, 8, 8],\n",
       "        [3, 3, 3,  ..., 8, 8, 8],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_labelIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([255], dtype=torch.uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_color[3,:,:].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
