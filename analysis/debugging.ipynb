{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import SegformerForImageClassification, SegformerModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from core.datasets.build import transform\n",
    "from core.configs import cfg\n",
    "from core.models.segformer import *\n",
    "from core.utils.hyperbolic import HyperMapper, HyperMLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def parse_args(args_str: str = None):\n",
    "    parser = argparse.ArgumentParser(description=\"Active Domain Adaptive Semantic Segmentation Training\")\n",
    "    parser.add_argument(\"-cfg\",\n",
    "                        \"--config-file\",\n",
    "                        default=\"\",\n",
    "                        metavar=\"FILE\",\n",
    "                        help=\"path to config file\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--proctitle\",\n",
    "                        type=str,\n",
    "                        default=\"HALO\",\n",
    "                        help=\"allow a process to change its title\", )\n",
    "    parser.add_argument(\n",
    "        \"opts\",\n",
    "        help=\"Modify config options using the command-line\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER\n",
    "    )\n",
    "\n",
    "    args_list = args_str.split() if args_str else None\n",
    "    args = parser.parse_args(args_list)\n",
    "\n",
    "    if args.opts is not None and args.opts != []:\n",
    "        args.opts[-1] = args.opts[-1].strip('\\r\\n')\n",
    "\n",
    "    cfg.set_new_allowed(True)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.SAVE_DIR = os.path.join(cfg.OUTPUT_DIR, cfg.NAME)\n",
    "    print(\"Saving to {}\".format(cfg.SAVE_DIR))\n",
    "    cfg.freeze()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to results/source_target/debug\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CfgNode({'MODEL': CfgNode({'NAME': 'deeplabv3plus_resnet101', 'NUM_CLASSES': 19, 'WEIGHTS': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth', 'FREEZE_BN': True, 'HYPER': True, 'CURVATURE': 1.0, 'REDUCED_CHANNELS': 64, 'HFR': True}), 'WANDB': CfgNode({'ENABLE': False, 'GROUP': 'source_target', 'PROJECT': 'active_domain_adapt', 'ENTITY': 'pinlab-sapienza'}), 'INPUT': CfgNode({'SOURCE_INPUT_SIZE_TRAIN': (1280, 720), 'TARGET_INPUT_SIZE_TRAIN': (1280, 640), 'INPUT_SIZE_TEST': (1280, 640), 'INPUT_SCALES_TRAIN': (1.0, 1.0), 'IGNORE_LABEL': 255, 'PIXEL_MEAN': [0.485, 0.456, 0.406], 'PIXEL_STD': [0.229, 0.224, 0.225], 'TO_BGR255': False}), 'DATASETS': CfgNode({'SOURCE_TRAIN': 'gtav_train', 'TARGET_TRAIN': 'cityscapes_train', 'TEST': 'cityscapes_val'}), 'SOLVER': CfgNode({'GPUS': [0], 'NUM_ITER': 60000, 'LR_METHOD': 'poly', 'BASE_LR': 0.001, 'LR_POWER': 0.5, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0005, 'WARMUP_ITERS': 600, 'BATCH_SIZE': 2, 'BATCH_SIZE_VAL': 1, 'CONSISTENT_LOSS': 0.0, 'NEGATIVE_LOSS': 1.0, 'NEGATIVE_THRESHOLD': 0.05, 'LCR_TYPE': 'l1'}), 'ACTIVE': CfgNode({'NAME': 'HALO', 'UNCERTAINTY': 'entropy', 'PURITY': 'radius', 'SETTING': 'RA', 'SELECT_ITER': [0, 15000, 30000, 40000, 50000], 'BUDGET': 0.05, 'RADIUS_K': 1, 'NORMALIZE': True, 'MASK_RADIUS_K': 5, 'K': 100, 'VIZ_MASK': False, 'RATIO': 0.05}), 'TEST': CfgNode({'BATCH_SIZE': 1, 'VIZ_SCORE': False, 'VIZ_WRONG': False, 'SAVE_EMBED': False}), 'NAME': 'debug', 'OUTPUT_DIR': 'results/source_target/', 'resume': '', 'SEED': -1, 'DEBUG': 0, 'PROTOCOL': 'source_target', 'SAVE_DIR': 'results/source_target/debug'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parse_args(\"-cfg ../configs/gtav/debug.yaml\")\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.build import build_dataset\n",
    "from core.datasets.cityscapes import cityscapesDataSet\n",
    "\n",
    "w, h = cfg.INPUT.TARGET_INPUT_SIZE_TRAIN\n",
    "trans_list = [\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD, to_bgr255=cfg.INPUT.TO_BGR255)\n",
    "]\n",
    "if cfg.INPUT.INPUT_SCALES_TRAIN[0] == cfg.INPUT.INPUT_SCALES_TRAIN[1] and cfg.INPUT.INPUT_SCALES_TRAIN[0] == 1:\n",
    "    trans_list = [transform.Resize((h, w)), ] + trans_list\n",
    "else:\n",
    "    trans_list = [\n",
    "                        transform.RandomScale(scale=cfg.INPUT.INPUT_SCALES_TRAIN),\n",
    "                        transform.RandomCrop(size=(h, w), pad_if_needed=True),\n",
    "                    ] + trans_list\n",
    "trans = transform.Compose(trans_list)\n",
    "\n",
    "target_set = cityscapesDataSet(\n",
    "                \"../datasets/cityscapes\",\n",
    "                \"../datasets/cityscapes_train_list.txt\",\n",
    "                max_iters=1000,\n",
    "                num_classes=19,\n",
    "                split=\"train\",\n",
    "                transform=trans,\n",
    "                cfg=cfg,\n",
    "                empty=False,\n",
    "            )\n",
    "\n",
    "target_loader = DataLoader(\n",
    "            dataset=target_set,\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/HALO/analysis/../core/datasets/cityscapes.py\", line 234, in __getitem__\n    label_mask = np.array(Image.open(datafiles[\"label_mask\"]), dtype=np.uint8)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'results/source_target/debug/gtMask/train/dusseldorf/dusseldorf_000157_000019_gtFine_labelIds.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pmandica/HALO/analysis/debugging.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(target_loader))\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/pmandica/HALO/analysis/../core/datasets/cityscapes.py\", line 234, in __getitem__\n    label_mask = np.array(Image.open(datafiles[\"label_mask\"]), dtype=np.uint8)\n  File \"/home/pmandica/miniconda3/envs/openmmlab/lib/python3.8/site-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'results/source_target/debug/gtMask/train/dusseldorf/dusseldorf_000157_000019_gtFine_labelIds.png'\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(target_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 640, 1280])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = batch['img'], batch['label']\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(2, 3, 720, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = SegformerForImageClassification.from_pretrained(\"nvidia/mit-b2\")\n",
    "feature_extractor = feature_extractor.segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = SegformerModel.from_pretrained(\"nvidia/mit-b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = feature_extractor.config\n",
    "config.num_labels = 19\n",
    "return_dict = config.use_return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = feature_extractor(img, output_hidden_states=True, return_dict=return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden_states = outputs.hidden_states if return_dict else outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = SegformerDecodeHead(config)\n",
    "head.post_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 90, 160])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = head(encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19, 160, 320])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegFormerSegmentationHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        num_classes: int,\n",
    "        num_features: int = 4,\n",
    "        hyper=False,\n",
    "        hfr=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Conv2d(channels * num_features, channels, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),  # why relu? Who knows\n",
    "            nn.BatchNorm2d(channels),  # why batchnorm and not layer norm? Idk\n",
    "        )\n",
    "        self.hyper = hyper\n",
    "        self.hfr = hfr\n",
    "        if hfr:\n",
    "            self.hfr = nn.Sequential(\n",
    "                nn.Linear(channels, channels),\n",
    "                nn.BatchNorm1d(channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(channels, channels),\n",
    "            )\n",
    "        if hyper:\n",
    "            self.mapper = HyperMapper()\n",
    "            self.hyper_mlr = HyperMLR(channels, num_classes)\n",
    "        else:\n",
    "            self.predict = nn.Conv2d(channels, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, size=None):\n",
    "        x = torch.cat(x, dim=1)\n",
    "        # x = x[0]\n",
    "        x = self.fuse(x)\n",
    "        feats = x.clone()\n",
    "        if self.hfr:\n",
    "            temp_out = x.permute(0, 2, 3, 1).contiguous().view(-1, x.size(1))\n",
    "            norm_weights = self.hfr(temp_out)\n",
    "            norm_weights = norm_weights.view(-1, x.size(2) * x.size(3), x.size(1))\n",
    "            norm_weights = torch.mean(norm_weights, dim=1, keepdim=False)\n",
    "            norm_weights = norm_weights.view(-1, x.size(1), 1, 1)\n",
    "            norm_weights = torch.clamp(norm_weights, min=1e-5)\n",
    "            temp_out = x.reshape(-1, x.size(1), x.size(2) * x.size(3))\n",
    "            temp_out = F.normalize(temp_out, dim=-1)\n",
    "            temp_out = temp_out.reshape(-1, x.size(1), x.size(2), x.size(3))\n",
    "            x = temp_out * norm_weights\n",
    "        if self.hyper:\n",
    "            feats = self.mapper.expmap(x, dim=1)\n",
    "            x = self.hyper_mlr(feats.double()).float()\n",
    "        else:\n",
    "            x = self.predict(x)\n",
    "        if size is not None:\n",
    "            x = F.interpolate(x, size=size, mode=\"bilinear\", align_corners=True)\n",
    "        return x, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = SegformerFeatureExtractor(reduce_labels=False)\n",
    "head = SegFormerSegmentationHead(512, 19, hyper=True, hfr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (BaseModelOutput, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pmandica/HALO/analysis/debugging.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m out, embeds \u001b[39m=\u001b[39m head(features, size\u001b[39m=\u001b[39;49m(\u001b[39m1024\u001b[39;49m, \u001b[39m2048\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/pmandica/HALO/analysis/debugging.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(x, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# x = x[0]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbluefin/home/pmandica/HALO/analysis/debugging.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuse(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (BaseModelOutput, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "out, embeds = head(features, size=(1024, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
